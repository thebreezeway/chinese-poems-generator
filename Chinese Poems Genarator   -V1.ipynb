{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Poetry Genarator - V1 -With RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba as jb\n",
    "import numpy as np\n",
    "from rnn_utils import *\n",
    "from nlp_helper import load_char_embeddings, load_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_to_index, index_to_char, index_to_vec = load_char_embeddings(\"../../data/embedding/sogou/char_embedding_plus_punctuation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_len =  6902 emb_dim =  (300,)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(char_to_index) + 2\n",
    "emb_dim = index_to_vec['0'].shape\n",
    "print(\"vocab_len = \", vocab_len, \"emb_dim = \", emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding fitures are between -1.685101 1.671867\n",
    "# append EOS and UNK to embedding matrixz\n",
    "np.random.seed(ord('E'))\n",
    "char_to_index['<EOS>'] = 6900\n",
    "index_to_char['6900'] = '<EOS>'\n",
    "index_to_vec['6900'] = np.random.rand(300,)\n",
    "\n",
    "np.random.seed(ord('U'))\n",
    "char_to_index['<UNK>'] = 6901\n",
    "index_to_char['6901'] = '<UNK>'\n",
    "index_to_vec['6901'] = np.random.rand(300,)\n",
    "\n",
    "#define /n as EOS\n",
    "char_to_index['\\n'] = 6900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tangshis = np.load(\"../../data/chinese-poetry-master/tangshi_v1_5yan.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'秦川雄帝宅，函谷壮皇居。'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangshis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset= tangshis\n",
    "# index = 5\n",
    "# batch_size = 4\n",
    "# mini_batch = []\n",
    "# Y = []\n",
    "# for c in range(12):\n",
    "#     char_batch = []\n",
    "#     char_batch_ix = []\n",
    "#     for i in range(batch_size): \n",
    "#         ix = char_to_index['<EOS>'] #初始化而已\n",
    "#         try:\n",
    "#             ix = char_to_index[dataset[index+i][c]]\n",
    "#         except KeyError:\n",
    "#             ix = char_to_index['<UNK>'] \n",
    "#         char_batch_ix.append(ix)\n",
    "#         char_batch.append(index_to_vec[str(ix)])\n",
    "#     Y.append(char_batch_ix)\n",
    "#     mini_batch.append(char_batch)\n",
    "# Y.append([char_to_index['<EOS>']]*4)\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_params(parameters):\n",
    "    np.save(\"saves/parameters_\"+str(parameters['endpoint'])+'.npy', parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, ix_to_char, ix_to_vec, seed, fixed_chars = None, padding = False ):\n",
    "    # Retrieve parameters and relevant shapes from \"parameters\" dictionary\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    vocab_size = by.shape[0]\n",
    "    n_a = Waa.shape[1]\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create the one-hot vector x for the first character (initializing the sequence generation). (≈1 line)\n",
    "    x = np.zeros((300,1))\n",
    "    # Step 1': Initialize a_prev as zeros (≈1 line)\n",
    "    a_prev = np.zeros((n_a,1))\n",
    "    \n",
    "    # Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate (≈1 line)\n",
    "    indices = []\n",
    "    \n",
    "    # Idx is a flag to detect a newline character, we initialize it to -1\n",
    "    idx = -1\n",
    "    \n",
    "    # Loop over time-steps t. At each time-step, sample a character from a probability distribution and append \n",
    "    # its index to \"indices\". We'll stop if we reach 50 characters (which should be very unlikely with a well \n",
    "    # trained model), which helps debugxging and prevents entering an infinite loop. \n",
    "    counter = 0\n",
    "    newline_character = char_to_ix['\\n']\n",
    "    \n",
    "    while (idx != newline_character and counter != 12):\n",
    "       \n",
    "        # Step 2: Forward propagate x using the equations (1), (2) and (3)\n",
    "        \n",
    "        a = np.tanh(np.dot( Wax, x) + np.dot(Waa, a_prev) + b)\n",
    "        z = np.dot(Wya, a) + by\n",
    "        y = softmax(z)\n",
    "        \n",
    "        \n",
    "        # for grading purposes\n",
    "        np.random.seed(counter+seed) \n",
    "        # Step 3: Sample the index of a character within the vocabulary from the probability distribution y\n",
    "        if fixed_chars!=None and counter<len(fixed_chars):\n",
    "            idx = char_to_ix[fixed_chars[counter]]\n",
    "        else:\n",
    "            while True:\n",
    "                idx = np.random.choice(range(vocab_size),p = y.ravel())\n",
    "                if not padding or idx != char_to_index[\"<EOS>\"]:\n",
    "\n",
    "                    break\n",
    "            \n",
    "        # Append the index to \"indices\"\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # Step 4: Overwrite the input character as the one corresponding to the sampled index.\n",
    "        x = index_to_vec[str(idx)].reshape(300,1)\n",
    "        \n",
    "        # Update \"a_prev\" to be \"a\"\n",
    "        a_prev = a\n",
    "        \n",
    "        # for grading purposes\n",
    "        seed += 1\n",
    "        counter +=1\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    if (counter == 50):\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n",
    "    # Forward propagate through time (≈1 line)\n",
    "    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n",
    "    \n",
    "    # Backpropagate through time (≈1 line)\n",
    "    gradients, a = rnn_backward(X, Y, parameters, cache)\n",
    "    \n",
    "    # Clip your gradients between -5 (min) and 5 (max) (≈1 line)\n",
    "    gradients = clip(gradients, 5)\n",
    "    \n",
    "    # Update parameters (≈1 line)\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    return loss, gradients, a[len(X)-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(dataset,index_to_char, char_to_index, index_to_vec, num_iterations = 120000, n_a = 64,gen_samples = 5,parameters = None, batch_size = 64,learning_rate= 0.01):\n",
    "    # Retrieve n_x and n_y from vocab_size\n",
    "    n_x, n_y = 300, len(char_to_index)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    if not parameters:\n",
    "        parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "        parameters['endpoint'] = 0\n",
    "        parameters['time'] = []\n",
    "    \n",
    "    # Initialize loss (this is required because we want to smooth our loss, don't worry about it)\n",
    "    # loss = get_initial_loss(vocab_size, dino_names)\n",
    "    \n",
    "    # Build list of all dinosaur names (training examples).\n",
    "    \n",
    "    # Shuffle list of all dinosaur names\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(dataset)\n",
    "    \n",
    "    # Initialize the hidden state of your LSTM\n",
    "    a_prev = np.zeros((n_a, batch_size))\n",
    "    j = 0\n",
    "    import time\n",
    "    time_start=time.time()\n",
    "    epoch_size = len(dataset)\n",
    "    try:\n",
    "    # Optimization loop\n",
    "        for j in range(parameters['endpoint'],parameters['endpoint'] + num_iterations):\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "\n",
    "            # Use the hint above to define one training example (X,Y) (≈ 2 lines)\n",
    "            index = j*batch_size%len(dataset)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            # 讲汉字转换为向量输入和索引输出，并处理未知字符。生成输入矩阵\n",
    "            X.append(np.zeros((300,batch_size)))\n",
    "            for c in range(12):\n",
    "                char_batch = []\n",
    "                char_batch_ix = []\n",
    "                for i in range(batch_size): \n",
    "                    ix = char_to_index['<EOS>'] #初始化而已\n",
    "                    try:\n",
    "                        ix = char_to_index[dataset[index+i][c]]\n",
    "                    except KeyError:\n",
    "                        ix = char_to_index['<UNK>'] \n",
    "                        \n",
    "                    char_batch_ix.append(ix)\n",
    "                    char_batch.append(index_to_vec[str(ix)])\n",
    "                    \n",
    "                X.append(np.array(char_batch).T)\n",
    "                Y.append(char_batch_ix)\n",
    "            \n",
    "            Y.append([char_to_index[\"<EOS>\"]]*batch_size)\n",
    "\n",
    "            \n",
    "\n",
    "            # Perform one optimization step: Forward-prop -> Backward-prop -> Clip -> Update parameters\n",
    "            # Choose a learning rate of 0.01\n",
    "            loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = learning_rate)\n",
    "\n",
    "            # Use a latency trick to keep the loss smooth. It happens here to accelerate the training.\n",
    "            # loss = smooth(loss, curr_loss)\n",
    "\n",
    "            # Every 2000 Iteration, generate \"n\" characters thanks to sample() to check if the model is learning properly\n",
    "            \n",
    "            print(\"进度:{}/{} epoches\".format(j*batch_size,epoch_size), end=\"\\r\")\n",
    "             \n",
    "            if j*batch_size % 512 == 0:\n",
    "                print(\"\\n耗时\",round(time.time()-time_start,3),\"s\")\n",
    "                print('Iteration: %d, Loss: %7f' % (j*batch_size, loss) + '\\n')\n",
    "\n",
    "                # The number of dinosaur names to print\n",
    "                seed = 0\n",
    "                for s in range(gen_samples):\n",
    "                    \n",
    "                    # Sample indices and print them\n",
    "                    sampled_indices = sample(parameters, char_to_index, index_to_char, index_to_vec, seed)\n",
    "                    print_sample(sampled_indices, index_to_char)\n",
    "                    print('')\n",
    "                    seed += 1  # To get the same result for grading purposed, increment the seed by one. \n",
    "\n",
    "                print('\\n')\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        \n",
    "        parameters['endpoint'] = j\n",
    "        time_end=time.time()\n",
    "        parameters['time'].append(round(time_end-time_start,3))\n",
    "        save_params(parameters)\n",
    "         \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " parameters= np.load(\"saves/parameters_360453.npy\")[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters['time'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进度:12189184/154162 epoches\n",
      "耗时 0.674 s\n",
      "Iteration: 12189184, Loss: 74.633679\n",
      "\n",
      "毛马翊棱賨，高极得营亭。\n",
      "定动没以为，忧贱报两年。\n",
      "何□萧萧枝，复开草木深。\n",
      "仙开不为此，蒲子不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12189696/154162 epoches\n",
      "耗时 2.5 s\n",
      "Iteration: 12189696, Loss: 74.560854\n",
      "\n",
      "毛马狸樵憔，好梦几眼积。\n",
      "定动余行在，耳臣即大名。\n",
      "何□萧萧舍，临城终相传。\n",
      "仙开不为此，慈许不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12190208/154162 epoches\n",
      "耗时 4.222 s\n",
      "Iteration: 12190208, Loss: 72.987428\n",
      "\n",
      "形随稽昼狭，处合自逢诗。\n",
      "定合如及将，缝茸转新天。\n",
      "何□萧萧宅，何之玉影亩。\n",
      "仙开不为此，慈许不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12190720/154162 epoches\n",
      "耗时 5.921 s\n",
      "Iteration: 12190720, Loss: 74.171253\n",
      "\n",
      "形随骎烛贞，近客几铁闻。\n",
      "定合如我是，陶朔便月多。\n",
      "何□萧萧挥，春间柳柳回。\n",
      "仙台多一去，遥见不从端。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12191232/154162 epoches\n",
      "耗时 7.655 s\n",
      "Iteration: 12191232, Loss: 76.603394\n",
      "\n",
      "形随悭丛悄，如照没相逢。\n",
      "辟食起月将，诸贱遭其多。\n",
      "何□萧萧识，调花遍舞脸。\n",
      "仙台多一去，遥见不从营。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12191744/154162 epoches\n",
      "耗时 9.483 s\n",
      "Iteration: 12191744, Loss: 75.838346\n",
      "\n",
      "形委辄忽遣，几戏当逾婚。\n",
      "定合如我是，陶杖自有多。\n",
      "何□萧萧识，调花遍舞脚。\n",
      "仙台多一去，囊深时将落。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12192256/154162 epoches\n",
      "耗时 11.18 s\n",
      "Iteration: 12192256, Loss: 75.572068\n",
      "\n",
      "形别绛鸾，虚天物同。<EOS>\n",
      "辟云无人在，始愁问地三。\n",
      "何□萧萧幸，春开献扇科。\n",
      "仙台多一去，彼此及不守。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12192768/154162 epoches\n",
      "耗时 12.842 s\n",
      "Iteration: 12192768, Loss: 74.469199\n",
      "\n",
      "形满夙悉屈，家民才短洪。\n",
      "定合如我了，参宣每日多。\n",
      "何□萧萧幸，春开舞鼓声。\n",
      "仙台多一去，囊深从将缺。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12193280/154162 epoches\n",
      "耗时 14.506 s\n",
      "Iteration: 12193280, Loss: 73.764965\n",
      "\n",
      "形委蒿焗绶，半意未关归。\n",
      "定合如我了，参宣每日多。\n",
      "何□萧萧殿，刀马惊闻真。\n",
      "仙台多一去，遥见不从疑。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12193792/154162 epoches\n",
      "耗时 16.156 s\n",
      "Iteration: 12193792, Loss: 76.558814\n",
      "\n",
      "形满燎苍苍，应沙无复闻。\n",
      "定合如我了，目遮见又来。\n",
      "何□萧萧殿，刀马惊闻真。\n",
      "仙台多一去，遥见日中烟。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12194304/154162 epoches\n",
      "耗时 17.833 s\n",
      "Iteration: 12194304, Loss: 72.557908\n",
      "\n",
      "形满奠耻徒，所食正视荣。\n",
      "定合如我了，奉荐道不多。\n",
      "何□萧萧宠，教此味阵重。\n",
      "仙台多一去，彼此及不久。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12194816/154162 epoches\n",
      "耗时 19.558 s\n",
      "Iteration: 12194816, Loss: 74.694882\n",
      "\n",
      "形别绛鸾，凤无客心。<EOS>\n",
      "辟乱如不在，始阻建所行。\n",
      "何□萧萧宠，露传献碎风。\n",
      "仙台多一去，遥见日中烟。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12195328/154162 epoches\n",
      "耗时 21.417 s\n",
      "Iteration: 12195328, Loss: 72.219368\n",
      "\n",
      "形随扪苍貘，岁民如丽坛。\n",
      "辟流无人在，始识早时我。\n",
      "乐襟劣辜谊，云节庆圣除。\n",
      "仙台多一去，遥见日中烟。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12195840/154162 epoches\n",
      "耗时 23.478 s\n",
      "Iteration: 12195840, Loss: 76.050314\n",
      "\n",
      "形随匮阙，念次具重。<EOS>\n",
      "辟何十人在，然染片水时。\n",
      "乐辊擎荆棘，举边落叶声。\n",
      "仙台多一去，遥见日中烟。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12196352/154162 epoches\n",
      "耗时 25.406 s\n",
      "Iteration: 12196352, Loss: 74.374112\n",
      "\n",
      "形随觞愯缈，共合无射赠。\n",
      "辟侧如我在，陶冕未能来。\n",
      "乐涤羞幽迹，极想复维接。\n",
      "仙台多一去，遥见日中烟。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12196864/154162 epoches\n",
      "耗时 27.424 s\n",
      "Iteration: 12196864, Loss: 74.387853\n",
      "\n",
      "形随觞壤，逸想别度。<EOS>\n",
      "辟流无人在，始识早时时。\n",
      "乐圃雁舛迟，田军喜景方。\n",
      "仙台多一去，遥见日中质。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12197376/154162 epoches\n",
      "耗时 29.379 s\n",
      "Iteration: 12197376, Loss: 73.934521\n",
      "\n",
      "形随旷沛宾，因谈共献琴。\n",
      "辟宝如不在，虚玄期已还。\n",
      "乐寝皇弦鹄，轻罗播阴光。\n",
      "仙台多一去，囊法日人旁。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12197888/154162 epoches\n",
      "耗时 31.324 s\n",
      "Iteration: 12197888, Loss: 74.238293\n",
      "\n",
      "邀随竺寝邑，高叶条芳阴。\n",
      "辟塞图不在，父哀作三年。\n",
      "乐圃凝蕙羽，树村汉吹神。\n",
      "仙台多一去，垂笔不有论。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12198400/154162 epoches\n",
      "耗时 33.282 s\n",
      "Iteration: 12198400, Loss: 74.496245\n",
      "\n",
      "邀随愧灶骸，曾似自抽务。\n",
      "辟宝如不在，虚翁无时还。\n",
      "乐炊覆屑骸，论转武池生。\n",
      "仙台多一岁，斋边不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12198912/154162 epoches\n",
      "耗时 35.278 s\n",
      "Iteration: 12198912, Loss: 74.008346\n",
      "\n",
      "邀随陌靖雁，共保经镜熙。\n",
      "辟何共后为，凤鬃此时时。\n",
      "乐瞻钓陀骢，精兼希劝旁。\n",
      "仙台多一几，藤稳两年春。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12199424/154162 epoches\n",
      "耗时 37.485 s\n",
      "Iteration: 12199424, Loss: 73.524758\n",
      "\n",
      "邀别妫澜沼，无马各求音。\n",
      "辟何十后为，勿谓王家不。\n",
      "乐瞻钓欺怨，春者思青血。\n",
      "仙台多一使，羡石不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12199936/154162 epoches\n",
      "耗时 39.362 s\n",
      "Iteration: 12199936, Loss: 73.344399\n",
      "\n",
      "邀随愧誉辱，天信正云琴。\n",
      "辟流无人在，喔涩越于来。\n",
      "乐霁辞萧陵，何能遂何期。\n",
      "仙台多一种，筋力月年英。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12200448/154162 epoches\n",
      "耗时 41.408 s\n",
      "Iteration: 12200448, Loss: 73.485661\n",
      "\n",
      "邀随愧释峻，高似未轻秋。\n",
      "辟宝如不在，勿遣太用新。\n",
      "乐瞻蒲丛幸，兵如吹埃风。\n",
      "仙台多一使，徒金日有春。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12200960/154162 epoches\n",
      "耗时 43.453 s\n",
      "Iteration: 12200960, Loss: 75.380271\n",
      "\n",
      "邀别嘶沐缨，高明未梦衣。\n",
      "辟足张三为志。<EOS>\n",
      "乐瞻蒲麓暗，侧进冷栏飞。\n",
      "仙台多一只，芙蓉元地朗。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12201472/154162 epoches\n",
      "耗时 45.412 s\n",
      "Iteration: 12201472, Loss: 75.748283\n",
      "\n",
      "尔方祐笙屐，得白想招功。\n",
      "辟断均以一，坚奴无人地。\n",
      "乐瞻僧幽趣，春水舞锦清。\n",
      "荷美都有发，闲山月上丝。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12201984/154162 epoches\n",
      "耗时 47.084 s\n",
      "Iteration: 12201984, Loss: 76.069300\n",
      "\n",
      "邀别矫猩鬓，无尽路寻材。\n",
      "辟云无不在，柏郁早时多。\n",
      "乐霁辞阮坂，跨走终相见。\n",
      "仙台多一只，芙蓉下从仙。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12202496/154162 epoches\n",
      "耗时 48.754 s\n",
      "Iteration: 12202496, Loss: 74.195691\n",
      "\n",
      "邀别雏萝鳖，高空应语闻。\n",
      "辟云无不在，霞迹自由来。\n",
      "乐瞻劳尘寒，春开烧丁花。\n",
      "仙台多一出，僧表月中形。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12203008/154162 epoches\n",
      "耗时 50.43 s\n",
      "Iteration: 12203008, Loss: 73.378600\n",
      "\n",
      "尔方愧碧侍，几古去何失。\n",
      "辟云无不在，柏冉余于之。\n",
      "乐炊覆辫沼，落水洗兰物。\n",
      "仙台多一出，蒲含下时轻。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12203520/154162 epoches\n",
      "耗时 52.148 s\n",
      "Iteration: 12203520, Loss: 75.502272\n",
      "\n",
      "尔方愧渊荆，小乐各愿智。\n",
      "辟云无不在，陶吏自三人。\n",
      "乐瞻宰宾歇，微风势朝风。\n",
      "仙台多一去，垂笔不他疑。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12204032/154162 epoches\n",
      "耗时 54.118 s\n",
      "Iteration: 12204032, Loss: 73.534369\n",
      "\n",
      "尔方愧渊卑，所尼类宫艇。\n",
      "辟断路人在，掩吟万里还。\n",
      "乐瞻宰拣鬓，胡门弄野飞。\n",
      "荷美日将处，潭方月上丝。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12204544/154162 epoches\n",
      "耗时 56.143 s\n",
      "Iteration: 12204544, Loss: 75.067411\n",
      "\n",
      "尔方愧怨戚，去住十波秋。\n",
      "辟云无不在，目罢度要之。\n",
      "乐霁辞颓示，朱国故情通。\n",
      "荷美日将处，疏明向我空。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12205056/154162 epoches\n",
      "耗时 58.096 s\n",
      "Iteration: 12205056, Loss: 75.017108\n",
      "\n",
      "尔方愧渊簿，因情想何忙。\n",
      "川川无日有，毕雁打出里。\n",
      "乐霁辞嗜简，何由颇逾回。\n",
      "荷美日将处，疏明向我空。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12205568/154162 epoches\n",
      "耗时 59.859 s\n",
      "Iteration: 12205568, Loss: 75.443555\n",
      "\n",
      "尔方愧怨戚，去住十波秋。\n",
      "川川无日有，挥焚亦不地。\n",
      "乐霁辞阶履，皆因遂稳作。\n",
      "荷美日将处，疏空两有财。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12206080/154162 epoches\n",
      "耗时 61.557 s\n",
      "Iteration: 12206080, Loss: 74.889102\n",
      "\n",
      "尔方祐帛棰，使昨得修营。\n",
      "川川无日有，攀幽山多多。\n",
      "乐瞻劳尘肠，何由复复传。\n",
      "荷美日将处，忆东两上势。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12206592/154162 epoches\n",
      "耗时 63.252 s\n",
      "Iteration: 12206592, Loss: 75.609692\n",
      "\n",
      "尔方芋戍颦，应眼老归烟。\n",
      "川川无日有，攀幽山地第。\n",
      "乐瞻劳尘肠，何由复复口。\n",
      "荷美日将处，潭方月上守。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12207104/154162 epoches\n",
      "耗时 64.984 s\n",
      "Iteration: 12207104, Loss: 75.437128\n",
      "\n",
      "尔方愧怨戚，去住十湖梁。\n",
      "川川无日有，攀莺入几年。\n",
      "乐瞻坟尘灭，何由谢雄花。\n",
      "荷美日将处，疏空两有沙。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12207616/154162 epoches\n",
      "耗时 66.665 s\n",
      "Iteration: 12207616, Loss: 74.911209\n",
      "\n",
      "尔方愧怨戚，去住十湖梁。\n",
      "川川无日有，攀莺入几年。\n",
      "乐霁辞赋铸，宝装闻横坐。\n",
      "荷美日将处，植心日有斯。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12208128/154162 epoches\n",
      "耗时 68.377 s\n",
      "Iteration: 12208128, Loss: 74.689625\n",
      "\n",
      "尔方愧怨戚，去住十湖梁。\n",
      "川川无日有，唇椒花下至。\n",
      "乐霁辞驹默，载自莫留东。\n",
      "荷美日将条，辞子不人存。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12208640/154162 epoches\n",
      "耗时 70.101 s\n",
      "Iteration: 12208640, Loss: 75.610641\n",
      "\n",
      "尔方愧怨戚，小歌想何诗。\n",
      "川川无日有，挥筷重未会。\n",
      "乐霁辞勋历，顺长润吹增。\n",
      "荷美日将条，辞子不有陪。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12209152/154162 epoches\n",
      "耗时 72.264 s\n",
      "Iteration: 12209152, Loss: 75.853766\n",
      "\n",
      "尔方愧怨戚，天节使帝冠。\n",
      "川川无日有，攀弊心日月。\n",
      "乐霁辞赋隐，须使添仙华。\n",
      "荷水还为此，烦学不中修。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12209664/154162 epoches\n",
      "耗时 74.316 s\n",
      "Iteration: 12209664, Loss: 76.419311\n",
      "\n",
      "尔方愧怨戚，小意正归亲。\n",
      "川川无日有，幸仕热新时。\n",
      "乐霁辞舌夷，何由终相见。\n",
      "荷水但一时，乎心不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12210176/154162 epoches\n",
      "耗时 76.213 s\n",
      "Iteration: 12210176, Loss: 75.928438\n",
      "\n",
      "尔方愧怨戚，天心如论言。\n",
      "川川无日有，邻髻加车时。\n",
      "乐霁辞颓哀，春首谢夺山。\n",
      "荷水但一时，糟马不从终。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12210688/154162 epoches\n",
      "耗时 78.3 s\n",
      "Iteration: 12210688, Loss: 74.654260\n",
      "\n",
      "尔方愧怨戚，小意未春知。\n",
      "川川无日有，叹适百年人。\n",
      "乐霁辞碧雀，翻夜震帝门。\n",
      "荷美日将条，疏空两年民。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12211200/154162 epoches\n",
      "耗时 80.291 s\n",
      "Iteration: 12211200, Loss: 74.639806\n",
      "\n",
      "尔方愧怨戚，去住半似闻。\n",
      "川川无日有，梨匣见成新。\n",
      "乐霁辞稻奏，齐令落粉香。\n",
      "荷美日将处，辞军不有媒。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12211712/154162 epoches\n",
      "耗时 82.323 s\n",
      "Iteration: 12211712, Loss: 73.601120\n",
      "\n",
      "尔方愧怨戚，去住女尔涂。\n",
      "川川无日有，挥僵欲来年。\n",
      "乐霁辞碧雀，翻夜瓦影门。\n",
      "荷美日将处，崩船时对吹。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12212224/154162 epoches\n",
      "耗时 84.329 s\n",
      "Iteration: 12212224, Loss: 75.830294\n",
      "\n",
      "尔方愧怨戚，去住女形残。\n",
      "川川无日有，鲍捎谁能由。\n",
      "极暮垂纶缆，玉节切阁门。\n",
      "夺车还一处，玄子不从抱。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12212736/154162 epoches\n",
      "耗时 86.269 s\n",
      "Iteration: 12212736, Loss: 73.625950\n",
      "\n",
      "尔方愧怨戚，去住半青翼。\n",
      "川川无日有，简杖自由来。\n",
      "极暮垂纶缆，玉节烟湿船。\n",
      "监王从是余，贱子不日活。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12213248/154162 epoches\n",
      "耗时 88.225 s\n",
      "Iteration: 12213248, Loss: 75.291211\n",
      "\n",
      "尔方愧怨戚，去住近云悬。\n",
      "川川无日有，邻砌入未来。\n",
      "极暮垂纶妓，宜爱终相见。\n",
      "专图从一好，孰馆不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12213760/154162 epoches\n",
      "耗时 89.924 s\n",
      "Iteration: 12213760, Loss: 73.046792\n",
      "\n",
      "尔方愧怨戚，去住近云扇。\n",
      "川川无日有，邻癖长新时。\n",
      "极暮垂纶茵，瑞山洗散船。\n",
      "尾网从为事，披色下两寻。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12214272/154162 epoches\n",
      "耗时 91.607 s\n",
      "Iteration: 12214272, Loss: 75.717198\n",
      "\n",
      "尔方愧怨戚，去住近云索。\n",
      "川川无日有，邻雁送来年。\n",
      "极暮垂纶霄，退老营命深。\n",
      "专图从一使，彼性但与衣。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12214784/154162 epoches\n",
      "耗时 93.319 s\n",
      "Iteration: 12214784, Loss: 75.106651\n",
      "\n",
      "尔方愧怨戚，去住近断柱。\n",
      "川川无日有，邻癖长新时。\n",
      "极暮垂纶霄，丽心湿松花。\n",
      "专图从一使，琪马不从落。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12215296/154162 epoches\n",
      "耗时 95.033 s\n",
      "Iteration: 12215296, Loss: 75.615729\n",
      "\n",
      "尔方愧怨戚，去住近沙摇。\n",
      "川旧图不在，勿遣爱地名。\n",
      "极暮垂纶茅，守会复客低。\n",
      "专图从一使，囊子不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12215808/154162 epoches\n",
      "耗时 96.723 s\n",
      "Iteration: 12215808, Loss: 74.829454\n",
      "\n",
      "尔方愧雀黍，路负如丝尘。\n",
      "川旧才时在，溪吾长不还。\n",
      "极暮垂纶沼，修路守阵花。\n",
      "尾网到中转，龟飞向日妆。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12216320/154162 epoches\n",
      "耗时 98.414 s\n",
      "Iteration: 12216320, Loss: 73.272800\n",
      "\n",
      "哭干盔帛匮，岁明未酒魂。\n",
      "川英水上上，欢翅声下去。\n",
      "极暮垂纶沼，冰根迷烟林。\n",
      "烧间次中水，藤服月上朱。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12216832/154162 epoches\n",
      "耗时 100.15 s\n",
      "Iteration: 12216832, Loss: 73.618220\n",
      "\n",
      "哭干谒舆饥，却死十龙闽。\n",
      "川英水上上，欢濑作元会。\n",
      "极暮垂纶霄，料声冷舞英。\n",
      "烧发能一长，遥若有人足。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12217344/154162 epoches\n",
      "耗时 101.811 s\n",
      "Iteration: 12217344, Loss: 74.473082\n",
      "\n",
      "哭干谒襟，杂半配色。<EOS>\n",
      "川旧才时在，溪伏晚来行。\n",
      "极暮垂纶贡，田平滑毛干。\n",
      "烧发能一网，涩景来不复。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12217856/154162 epoches\n",
      "耗时 103.479 s\n",
      "Iteration: 12217856, Loss: 74.131131\n",
      "\n",
      "哭干嗟鸥寝，高似自闻君。\n",
      "川川无日有，简柚通五时。\n",
      "极岐窥鹿驭，何由终相见。\n",
      "烧发能一网，庸马及人封。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12218368/154162 epoches\n",
      "耗时 105.307 s\n",
      "Iteration: 12218368, Loss: 76.280917\n",
      "\n",
      "哭干谒寝骄，天节使御然。\n",
      "川调水日中，宠筱转于行。\n",
      "极岐窥鹿儒，故日归清风。\n",
      "烧指已一处，闲节不不知。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12218880/154162 epoches\n",
      "耗时 107.273 s\n",
      "Iteration: 12218880, Loss: 76.108280\n",
      "\n",
      "哭干谒寝骄，据改未足弃。\n",
      "川英水上上，眉覆镇人多。\n",
      "极暮垂纶绮，观金标丽风。\n",
      "烧间次中水，羌歌多年遇。\n",
      "<EOS>\n",
      "\n",
      "\n",
      "进度:12219392/154162 epoches\n",
      "耗时 109.347 s\n",
      "Iteration: 12219392, Loss: 73.566180\n",
      "\n",
      "兴平苍茫啾，同似作秋策。\n",
      "调何曾上将，尤邑未能来。\n",
      "极暮垂纶芽，吹波烧采街。\n",
      "烧杯大将没，敬力不有吹。\n",
      "<EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进度:12219520/154162 epoches\r"
     ]
    }
   ],
   "source": [
    "parameters=model(tangshis, index_to_char, char_to_index, index_to_vec, num_iterations = 10000,batch_size=64,parameters=parameters, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_params(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "扶看云水曲，数讶片寒涛。\n",
      "\n",
      "近言披云里，云摧动丘峰。\n",
      "\n",
      "好借经旅细，魑盖甚何劳，\n",
      "\n",
      "凤霜龙城上，哀歌凌干清。\n",
      "\n",
      "何时乱帝星。<EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成 诗句\n",
    "seed = 10\n",
    "for name in range(5):\n",
    "                \n",
    "    # Sample indices and print them\n",
    "    sampled_indices = sample(parameters, char_to_index, index_to_char, index_to_vec, seed, fixed_chars=\"\", padding = False)\n",
    "    print_sample(sampled_indices, index_to_char)\n",
    "    seed += 1  # To get the same result for grading purposed, increment the seed by one. \n",
    "      \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
